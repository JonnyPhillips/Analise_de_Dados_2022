---
title: "Testes Estatísticos e Regressões"
output:
  distill::distill_article:
    toc: true
    toc_float: true
    toc_depth: 1
---

<style>
div.green { background-color:#e5f5e0; border-radius: 5px; padding: 20px;}
</style>

<style>
div.orange { background-color:#fee6ce; border-radius: 5px; padding: 20px;}
</style>

<style>
div.blue { background-color:#deebf7; border-radius: 5px; padding: 20px;}
</style>

<style>
div.purple { background-color:#9e9ac8; border-radius: 5px; padding: 20px;}
</style>


```{r setup, include=FALSE, echo=F}
knitr::opts_chunk$set(echo = T, eval=T, highlight=T)
library("nycflights13")
library("tidyverse")
library("rmarkdown")
library("knitr")
library("kableExtra")
library("broom")
filter <- dplyr::filter
```

# Introdução

Não se preocupe se você não esteja treinado em métodos quantitativos - não discutimos os detalhes da estatística aqui. Mas é comum aplicar um teste simples ou uma regressão aos nossos dados para avaliar alguma hipótese, e sabendo como fazer isto é um bom treinamento para construir fluxos de análise mais complexos para outros objetivos também. 

Os pontos cruciais de testes estatísticos são os seguintes:

1. Temos dados de pelo menos uma variável e queremos avaliar se um 'fato' sobre estes dados é verdade. 
2. Então comparamos os nossos dados com 
3. Mas existem duas formas de 'passar' um teste: (i) os dados são realmente 
Explain p-value simply

As funções de testes estatísticos e regressões são mais diversas e menos padronizadas que as funções que já discutimos. Assim, é crucial entender o *classe/tipo de objeto* que a função espera. A nossa tarefa é usar o nosso pipe para preparar os dados no classe/formato apropriado. 

A implicação é que cada teste gera vários valores de interesse que temos que interpretar e explicar, não é simplesmente 'verdade' vs. 'falsa'. 

# Testes de Normalidade

O nosso primeiro teste é um teste de como os nossos dados são distribuidos. Dados contínuos normalmente formam uma distribuição 'normal' quando temos um número razoável de observações. Podemos confirmar se os nossos dados fossem 'normal' com um teste que se chama o teste Shapiro-Wilk. Ele compara os nossos dados com uma distribuição normal perfeita e avalia quanto longe de normal são os nossos dados. 

Usamos o teste Shapiro-Wilk através da função `shapiro.test()` e ela espera um vetor dos valores da variável que queremos testar. Então temos que isolar um vetor (não um tibble) para encaminhar usando a função 'pull'. Vamos avaliar se os atrasos são distribuidos normalmente:

```{r, eval=F}
flights %>% 
  pull(dep_delay) %>% 
  shapiro.test()
```

Ah, o R pediu que limitamos os nossos dados para um máximo de 5000 para simplificar o teste. Tudo bem, vamos pegar uma amostra aleatória de 3000 observações:

```{r}
teste_normalidade <- flights %>% sample_n(3000) %>% 
  pull(dep_delay) %>% 
  shapiro.test()

teste_normalidade
```

Ótimo - veja o resultado do teste: Há um teste estatístico 'W' e um valor 'p' para avaliar a significância do teste. O valor 'p' é bem pequeno aqui, indicando que tem pouco chance que os nossos dados são normais. 

<div class = "blue">
**Habilidade Básica de Programação: Números Científicos**

Às vezes parece que os nossos números foram corrompidos, sobretudo com testes estatísticos: Qual espécie de número é "2.2e-6"?? 

É um número, sim, um número muito grande ou muito pequeno que o R escolha mostra no formato 'científico'. "2.2e-6" indica o número de dígitos que temos que mexer o ponto decimal (a vírgula) para chegar no valor final. Aqui é igual a 0,0000022. Se for "2.2e+6", seria 2200000,0.

Você não precisa fazer nada, o valor é salvo com um número completo com todos os seus dígitos. A diferença é só na *apresentação* do valor na tela. 

Mas é verdade que às vezes preferimos valores mais fáceis para interpretar. Uma dica para indicar ao R não usar o formato científico é usar o seguinte código no início do seu script:

```{r, eval=F}
options(scipen=999)
```

</div>

Dá para verificar que a distribuição não parece normal com um gráfico de densidade. Em vez de uma distribuição simétrica, temos uma cauda longa no lado direito. 

```{r}
flights %>% 
  ggplot() +
  geom_density(aes(x=dep_delay)) +
  xlim(0,100)
```

Qual foi o tipo de objeto que foi criado pela `shapiro.test()`? 

```{r}
class(teste_normalidade)
```

É do tipo 'htest', que é um formato proprietário que é muito difícil incorporar em nosso texto, ou em uma tabela. Por exemplo, eu quero inserir a frase "O teste Shapiro-Wilk de normalidade da variável dep_delay tem valor 'p' de X". Como eu posso inserir 'X' com in-line código?

Existe uma outra biblioteca/função dedicada a ajudar nessa situação, simplificando e padronizando o resultado de testes estatísticos. Qual é o objeto com quem estamos mais acostumados a trabalhar? É o tibble, lembre que quase tudo foi um tibble! Isso é o mágico da biblioteca `broom` e a função `tidy` - ela transforme os resultados de testes estatísticos em um tibble:

```{r}
#install.packages("broom")
library(broom)

teste_normalidade <- flights %>% sample_n(3000) %>% 
  pull(dep_delay) %>% 
  shapiro.test() %>% 
  tidy()
```

```{r, eval=F}
teste_normalidade
```

```{r, echo=F}
teste_normalidade %>% paged_table()
```


Muito melhor! Agora temos todos os detalhes do teste num tibble, e é fácil extrair os valores desejados, por exemplo:

O teste Shapiro-Wilk de normalidade da variável dep_delay tem valor 'p' de `` `r
teste_normalidade %>% pull(p.value) %>% round(3)` ``. 

O teste Shapiro-Wilk de normalidade da variável dep_delay tem valor 'p' de `r teste_normalidade %>% pull(p.value) %>% round(3)`.

Pode usar `tidy` depois da maioria de testes estatísticos, e também regressões para simplificar a apresentação dos resultados.

# Testes de Médias

Uma outra família de testes estatísticos é testes de médias, amplamante conhecidos como 't-tests'. Começamos com um teste simples: a nossa média é estatisticamente diferente de um valor específico? Imagine, por exemplo, que as companhias aéreas tinham um atraso médio de 13.4 minutos em 2012 - o valor média em 2013 foi diferente?

Este teste exige uma comparação entre os nossos dados e o valor '13.4', então vamos encaminhar o vetor de atrasos para a função `t.test()`, especificando o argumento `mu` para a média padrão com que queremos comparar. E não esquecemos de usar `tidy()` no final para simplificar o resultado:

```{r, eval=F}
teste_media <- flights %>% filter(origin!="LGA") %>% 
  pull(dep_delay) %>%
  t.test(mu=13.4) %>% 
  tidy()
```

```{r, echo=F}
teste_media <- flights %>% filter(origin!="LGA") %>% 
  pull(dep_delay) %>%
  t.test(mu=13.4) %>% 
  tidy() %>%
  paged_table()
```

Recebemos muitas informações aqui: a média dos nossos dados é 13.66, pouco acima de 13.4, o intervalo de confiança (de 95%) é de 13.49 a 13.83, e o valor 'p' é 0.0018, debaixo da padrão comum de 0.05. Então o restulado fica estatisticamente significativa.

Para comunicar os resultados de t-test, é frequentemente útil gerar gráficos para mostrar o intervalo de confiança. Como podemos construir um gráfico deste tipo? Vamos começar com o parte mais fácil: colocamos a média dos nossos dados (um ponto com `geom_point` e uma linha para indicar o ponto de comparação (uma linha com `geom_hline`):

```{r}
teste_media %>% mutate(Variavel="Atraso na partida") %>% 
  ggplot() +
  geom_point(aes(x=Variavel, y=estimate)) +
  geom_hline(yintercept=13.4, lty=2, color="blue")
```

Observe aqui que adicionamos uma coluna com o nome da variável em nosso tibble antes de visualizar para que podemos incorporar o nome da aquele variável em nosso gráfico. O formato dos resultados num tibble facilita bastante a preparação do gráfico.

Agora, vamos adicionar uma linha que mostra o intervalo de confiança, com a geometria `geom_errorbar()`, que exige duas variáveis: o `ymin` e `ymax` para definir os limites da linha baseado nos valores em nosso tibble:

```{r}
teste_media %>% mutate(Variavel="Atraso na partida") %>% 
  ggplot() +
  geom_point(aes(x=Variavel, y=estimate)) +
  geom_hline(yintercept=13.4, lty=2, color="blue") +
  geom_errorbar(aes(x=Variavel, ymin=conf.low, ymax=conf.high), width=0.1)
```

É fácil ver no gráfico que o intervalo de confiança de 95% não sobreposiciona o valor de 13.4, significando que o atraso subiu em 2013. 

## Comparando Médias

Que tal se não temos um ponto de comparação fixa, mas queremos comparar se a média em um grupo é diferente da média num outro grupo? Isso significa que dividimos os nossos dados baseado numa variável categôrica em nosso tibble, e comparamos as duas distribuições. Por exemplo, queremos comparar se o atraso média do aeroporto 'EWR' é estatisticamente diferente do atraso média no aeroporto 'JFK'.

Podemos continuar usando a função `t.test`, mas agora que temos que definir uma variável discreta e uma variável contínua, precisamos encaminhar o nosso tibble completo e não uma variável única, então não precisamos do passo de `pull()`. Em vez disso, e dado que estamos usando funções fora do tidyverse, temos que indicar para `t.test` que ela deve trabalhar com os dados que estamos encaminhando pelo pipe com `data=.`. (Lembre-se que o `.` significa para R usar os dados produzidos no fluxo do pipe anterior). 

Finalmente, há mais uma diferença quando temos que especificar uma variável contínua para dividar baseado numa variável discreta. Vários testes, incluindo `t.test`, exigem que definimos este análise usando uma fórmula, com a variável conínua na esquerda e a variável discreta (os grupos que queremos comparar) na direita: `dep_delay ~ origin`.

<div class = "blue">
**Habilidade Básica de Programação: Fórmulas**

Uma fórmula é simplesmente uma sintaxe para comparar uma variável dependente (o resultado que queremos comparar) e variáveis independentes (que dividem os nossos dados em grupos ou nós achamos podem correlacionar com a variável dependente). 

A variável dependente *sempre* fica na esquerda, e está separada das variáveis independentes com o símbolo `~`. Por exemplo: 

`dependente ~ independente`

Podemos adicionar mais vaiáveis independentes com o símbolo '+': 

`dependente ~ independente1 + independente2`

</div>

```{r, eval=F}
flights %>% filter(origin!="LGA") %>% 
  t.test(dep_delay ~ origin, data=.) %>% 
  tidy()
```

```{r, echo=F}
flights %>% filter(origin!="LGA") %>% 
  t.test(dep_delay ~ origin, data=.) %>% 
  tidy() %>%
  paged_table()
```

Note que filtramos os dados para deixar apenas dois valores na variável `origin` (o t-test só funciona com dois grupos). O resultado contém muita informação - o 'estimate' é a diferença de médias, o 'estimate1' a média no primeiro aeroporto ('EWR'), e o 'estimate2' a média no segundo aeroporto ('JFK'). E temos o valor 'p' e o intervalo de confiança. Parece que realmente tem uma diferencá significativa, com um atraso média maior em Newark (EWR).

Este tipo de teste é muito comum porque sempre queremos comparar entre grupos. Por exemplo, um t-test deste tipo é a análise feito quando rodamos um experimento para comparar dois grupos: tratamento e controle.

# Testes de Correlação

Sabemos que existe uma associação entre o atraso média e o aeroporto - entre uma variável contínua e uma variável discreta. Como podemos comparar a associação entre duas variáveis contínuas? Por exemplo, atraso (`dep_delay`) e horário de partida (`dep_time`)? 

Associação neste caso se chama 'correlação' e compara todos os valores das daus variáveis, e não simplesmente as médias. A avaliação do teste de correlação é calcular o coeficiente de correlação (de Pearson, por padrão; basicamente a inclinação da linha entre os pontos), que pode ser positivo ou negativo, e comparar com zero. 

Rodando o teste é fácil: encaminhamos o nosso tibble para `cor.test()`, com `data=.`, e a fórmula agora tem duas variáveis independentes e nenhuma dependente (dado que estamos tratando as variáveis igualmente). Como sempre, `tidy()` ajuda para organizar os resultados.

```{r, eval=F}
flights %>% 
  cor.test(~ dep_delay + dep_time, data=.) %>%
  tidy()
```

```{r, echo=F}
flights %>% 
  cor.test(~ dep_delay + dep_time, data=.) %>%
  tidy() %>%
  paged_table()
```

Os resultados indicam um coeficiente de correlação de 0.26 (positivo), e um valor 'p' de zero. 

É fácil usar um gráfico de pontos e uma linha para mostrar esta correlação:

```{r}
flights %>% sample_n(1000) %>% 
  ggplot() +
  geom_point(aes(x=dep_time, y=dep_delay)) +
  geom_smooth(aes(x=dep_time, y=dep_delay), method="lm")
```


## Testes de Correlação de Variáveis Categóricas (Chi-squared)

Para completar a tipologia de testes, como podemos comparar duas variáveis categôricas? Por exemplo, queremos comparar as variáveis `dest` (destino) e `carrier` (companhia aérea) para saber - estatisticamente - se as mesmas companhias voam de cada aeroporto.

Nesta circunstância, é apropriado aplicar um teste 'chi-squared', usando a função `chisq.test()`. O formato que a função exige é uma 'tabela de contingência' - todas as combinações das duas variáveis possíveis e o número de observações para cada combinação.

Felizmente, é fácil construir essa tabela com a função `table()`, com um `select` anterior para definir as duas variáveis que queremos comparar:

```{r}
flights %>% select(origin, carrier) %>% 
  table()
```

Faz sentido? A tabela mostra o número de voos de cada aeroporto e cada companhia aérea. É meio-óbvio que a distribuição das companhias é diferente por cada aeroporto, mas vamos testar isso estatisticamente:

```{r, eval=F}
flights %>% select(origin, carrier) %>% 
  table() %>% 
  chisq.test() %>%
  tidy()
```

```{r, echo=F}
flights %>% select(origin, carrier) %>% 
  table() %>% 
  chisq.test() %>%
  tidy() %>%
  paged_table()
```

O valor de 'p' de zero indica que realmente existe uma diferença nas companhias que voam de cada aeroport. 

# Regressões Simples

Regressão é correlação. Nada muito mais complexo que isso, então não fica com medo - rodar uma regressão é uma linha única de código. Existem variadades infinitas de regressões, e escolhindo o mais apropriado é fora do curso. 

Começamos com a regressão mais simples, um modelo linear, apropriado para variáveis dependentes contínuos. A função é `lm()`, e indicando `data=.` podemos passar os nossos dados direitamente para ela. É só inserir a fórmula que define a nossa regressão, como sempre com a variável dependente na esquerda e as variáveis independentes na direita. Por exemplo:

```{r}
flights %>% lm(dep_delay ~ dep_time, data=.)
```

Okay, o resultado aqui é complexo e não muito claro. Há duas opções para pedir mais detalhes da regressão:

1. Use a função `summary()` para gerar uma tabela de regressão e várias estatísticas, mas num formato terrível. Isto é útil para uma avaliação inicial, mas não ajuda para relatórios profissionais.

```{r}
flights %>% lm(dep_delay ~ dep_time, data=.) %>%
  summary()
```

2. Use a função `tidy()` para gerar um tibble com os coeficientes e os seus estatísticos. 

```{r}
flights %>% lm(dep_delay ~ dep_time, data=.) %>%
  tidy()
```

A segunda opção e geralmente mais útil para relatórios, mas vamos ver em breve alternativas para gerar direitamente tabelas mais bonitas. 

Observe que gerando regressões mais complexas só precisa de ajustes na fórmula. Por exemplo para adicionar mais variáveis independentes:

```{r}
flights %>% lm(dep_delay ~ dep_time + origin, data=.) %>% summary()
```

Para especificar uma relacionamento entre uma variável independente e o dependente *não*-linear, ex. quadrático, temos que usar a função `I()`, por exemplo:

```{r}
flights %>% lm(dep_delay ~ dep_time + I(dep_time^2), data=.) %>% summary()
```

## Tabelas de Resultados de Regressões

É muito comum compartilhar os resultados da nossa regressão em uma tabela. Existem várias funções que facilitam este processo; vamos usar `stargazer`, da biblioteca do mesmo nome. Podemos preparar tabelas em vários formatos, para HTML ou para PDF (com latex). Se quisemos tabelas de HTML, temos que especificar o argumento `type="html"`. 

Cuidado: Existe mais uma ajuste necessário. Lembre-se das opções de chunks que especificamos, como `echo=FALSE` para não mostrar o nosso código? Com stargazer temos que especificar `results='asis'` nas opções de chunk para que o resultado saia corretamente.

```{r, results='asis' }
library(stargazer)
flights %>% lm(dep_delay ~ dep_time + origin, data=.) %>%
  stargazer(type="html")
```

Uma tabela bem-formatada com pouco esforço! É possível ajustar todos os elementos da tabela usando os argumentos da função `stargazer`. 

Em caso que você querer comparar dois modelos parecidos *na mesma tabela*, é só salvar as duas regressões como objetos, e encaminhar eles huntos na forma de uma `list()` para `stargazer`:

```{r, results='asis'}
reg1 <- flights %>% lm(dep_delay ~ dep_time, data=.)
reg2 <- flights %>% lm(dep_delay ~ dep_time + origin, data=.)

list(reg1, reg2) %>% stargazer(type="html")
```

# Modelos Alternativos

Uma regressão linear é apenas uma das possibilidades. O tipo de regressão reflete o tipo de dados na variável dependente. Por exemplo, dados binários exigem um modelo de regressão de tipo 'logit' (ou 'probit'). 

Para acomodar uma variedade de modelos vamos aproveitar do pacote `zelig()` que aceita várias possibilidades. Primeiro, usamos o `model="logit"`. 

```{r}
#install.packages("Zelig")
library(Zelig)

flights %>% mutate(atraso=case_when(dep_delay>0~1,
                                    TRUE~0)) %>%
  zelig(atraso ~ origin, data=., model="logit")
```

A tabela abaixo mostra a função sugerida (existe muitos) para cada tipo de dados usando `zelig()`:

```{r, eval=F}
tibble(Tipo_Dados=c("Contínuo", "Binário", ">2 Categorias", "Categorias Ordenadas", "Contagem (número de eventos)"),
                     Model=c("`ls`", "`logit`", "`mlogit`", "`ologit`", "`poisson`"))
```

```{r, echo=F}
tibble(Tipo_Dados=c("Contínuo", "Binário", ">2 Categorias", "Categorias Ordenadas", "Contagem (número de eventos)"),
                     Model=c("`ls`", "`logit`", "`mlogit`", "`ologit`", "`poisson`")) %>%
  paged_table()
```

Note que o zelig precisa mais um passo para encaminhar os resultados ao Stargazer para criar tabelas:

```{r, eval=F}
flights %>% mutate(atraso=case_when(dep_delay>0~1,
                                    TRUE~0)) %>%
  zelig(atraso ~ origin, data=., model="logit") %>%
  from_zelig_model() %>%
  stargazer(type="html")
```

```{r, results='asis', echo=F}
flights %>% mutate(atraso=case_when(dep_delay>0~1,
                                    TRUE~0)) %>%
  zelig(atraso ~ origin, data=., model="logit") %>%
  from_zelig_model() %>%
  stargazer(type="html")
```

## Previsões e Resíduos de Regressões

Uma regressão também gera novos dados para cada observação - por exemplo, o valor da variável dependente prevista por nossa regressão, os `resíduos` entre o valor atual e o valor previsto. Dado que há um valor para cada observação, faz sentido adicionar estes valores ao nosso banco de dados (tibble) original. 

A função `augment()` (do pacote `broom`) permite isso - começando com o nosso modelo radado acima, `augment()` gera um novo tibble com os dados originais usados na regressão mais colunas para atributos da regressão.

```{r}
reg1 %>% augment()
```

## Gráficos de Previsões de Regressões

Uma regressão é também uma 'maquina' para prever o que vai acontecer com a variável dependente quando as variáveis independentes assumem valores específicos. Claro que a qualidade da previsão pode ser terrível se o modelo não seja correta. 

Com o `zelig`, é fácil gerar essas previsões. Seguimos a nossa regressão com uma definição dos valores de variáveis independentes usando a função `setx()`, com um valor para cada variável, e depois a função sim(), sem argumento. Por exemplo, se rodamos um modelo linear para prever o atraso com o horário de partida das 5h:

```{r}
flights  %>%
  zelig(dep_delay ~ dep_time, data=., model="ls") %>% 
  setx(dep_time=0500) %>%
  sim()

flights  %>%
  lm(dep_delay ~ dep_time, data=.) 
```

Qual é o resultado? São valores previstos - a linha de 'pv' é a previsão do atraso se voamos as 5h da manhã, -3.7 minutos na média. 

```{r}
flights  %>%
  zelig(dep_delay ~ dep_time, data=., model="ls") %>% 
  setx(dep_time=1700) %>%
  sim()
```

Em contraste, quando especificamos o horário de partido das 17h, o atraso média é 19 minutos. 

Finalmente, podemos avaliar a diferença em atraso entre os dois horários, com a adição da função `setx1()`:

```{r}
flights  %>%
  zelig(dep_delay ~ dep_time, data=., model="ls") %>% 
  setx(dep_time=0500) %>%
  setx1(dep_time=1700) %>%
  sim()
```

Agora, foca-se na linha `fd`, que mostra uma diferença de 25.7 minutos na média: muito melhor voar cedo!

## Simulações de Regressões

Finalmente, às vezes é útil gerar milhares de *simulações* das previsões de modelos de regressão. Assim, podemos avaliar dados além da média, por exemplo, qual a chance de atrasar mais de uma hora adicional se voamos as 17h em vez das 5h?

No final do fluxo de análise de `zelig`, adicionamos a função `zelig_qi_to_df()`

```{r}
flights_sims <- flights  %>%
  zelig(dep_delay ~ dep_time, data=., model="ls") %>% 
  setx(dep_time=0500) %>%
  setx1(dep_time=1700) %>%
  sim() %>%
  zelig_qi_to_df()
```

Agora o resultado é o nosso objeto favorito, um tibble (ou pelo menos um data.frame)! Com ele, podemos usar todas as nossas habilidades anteriores. O nosso objetivo é comparar as primeiras 1000 simulações para a váriavel de `expected_value` para o horário de 5h com os últimos 1000 simulações para 17h.

Primeiro, vamos virar a tabela para que temos duas col

```{r}
flights_sims %>% select(`temp_fitted[i, ]`, predicted_value) %>% 
  mutate(ID=rep(1:1000, 2)) %>%
  pivot_wider(names_from="temp_fitted[i, ]", values_from="predicted_value") %>%
  mutate(Diferenca=`1700`-`500`) %>%
  ggplot() +
  geom_density(aes(x=Diferenca))
  
```


Por exemplo, podemos gerar um gráfico de densidade para entender melhor a diferença nos riscos de atraso. 

```{r}
flights_sims %>%
  ggplot() +
  geom_density(aes(x=))
```




<!-- https://stats.idre.ucla.edu/other/mult-pkg/whatstat/ -->
<!-- install.packages("Zelig") problem -->
